{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Customer Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install watson-machine-learning-client==1.0.375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade scikit-learn==0.20.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-start the Kernel now !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, svm\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import PolynomialFeatures, LabelEncoder, StandardScaler\n",
    "import sklearn.feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from sklearn import metrics\n",
    "import pixiedust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Dataset\n",
    "\n",
    "From a telecommunications company. It includes information about:  \n",
    "- Customers who left within the last month – the column is called Churn\n",
    "\n",
    "- Services that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n",
    "\n",
    "- Customer account information – how long they’ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n",
    "\n",
    "- Demographic info about customers – gender, age range, and if they have partners and dependents\n",
    "\n",
    "Link for getting the dataset: [https://community.watsonanalytics.com/wp-content/uploads/2015/03/WA_Fn-UseC_-Telco-Customer-Churn.csv](https://community.watsonanalytics.com/wp-content/uploads/2015/03/WA_Fn-UseC_-Telco-Customer-Churn.csv)\n",
    "\n",
    "Link for other datasets: [https://www.ibm.com/communities/analytics/watson-analytics-blog/guide-to-sample-datasets/](https://www.ibm.com/communities/analytics/watson-analytics-blog/guide-to-sample-datasets/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2. Loading Our Dataset\n",
    "\n",
    "Click on the cell below to highlight it.\n",
    "\n",
    "Then go to the `Files` section to the right of this notebook and click `Insert to code` for the data you have uploaded. Choose `Insert pandas DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place cursor below and insert the Pandas DataFrame for your uploaded data\n",
    "# Make sure the variable is named `df_data_1` for the line `df_data_1 = pd.read_csv(body)`\n",
    "\n",
    "import os, pandas as pd\n",
    "# Add asset from file system\n",
    "df_data_2 = pd.read_csv(os.environ['DSX_PROJECT_DIR']+'/datasets/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "df_data_2.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data = df_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Checking that everything is correct\n",
    "pd.set_option('display.max_columns', 30)\n",
    "customer_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3. Get some info about our Dataset and whether we have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# After running this cell we will see that we have no missing values\n",
    "customer_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Drop customerID column\n",
    "customer_data = customer_data.drop('customerID', axis=1)\n",
    "customer_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Convert TotalCharges column to numeric as it is detected as object\n",
    "new_col = pd.to_numeric(customer_data.iloc[:, 18], errors='coerce')\n",
    "new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Modify our dataframe to reflect the new datatype\n",
    "customer_data.iloc[:, 18] = pd.Series(new_col)\n",
    "customer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Check if we have any NaN values\n",
    "customer_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp = Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "\n",
    "customer_data.iloc[:, 18] = imp.fit_transform(customer_data.iloc[:, 18].values.reshape(-1, 1))\n",
    "customer_data.iloc[:, 18] = pd.Series(customer_data.iloc[:, 18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Check if we have any NaN values\n",
    "customer_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "customer_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4. Descriptive analytics for our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Describe columns with numerical values\n",
    "pd.set_option('precision', 3)\n",
    "customer_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Describe columns with objects\n",
    "customer_data.describe(exclude=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Find correlations\n",
    "customer_data.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5. Visualize our Data to understand it better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Plot Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "aggregation": "COUNT",
      "clusterby": "Churn",
      "handlerId": "barChart",
      "keyFields": "tenure",
      "rendererId": "brunel",
      "sortby": "Keys ASC",
      "timeseries": "false",
      "title": "Tenure",
      "valueFields": "MonthlyCharges"
     }
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Using Pixiedust for visualization\n",
    "display(customer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot Tenure Frequency count\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set_palette(\"hls\", 3)\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax = sns.countplot(x=\"tenure\", hue=\"Churn\", data=customer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot Tenure Frequency count\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set_palette(\"hls\", 3)\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax = sns.countplot(x=\"Contract\", hue=\"Churn\", data=customer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot Tenure Frequency count\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set_palette(\"hls\", 3)\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax = sns.countplot(x=\"TechSupport\", hue=\"Churn\", data=customer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create Grid for pairwise relationships\n",
    "gr = sns.PairGrid(customer_data, size=5, hue=\"Churn\")\n",
    "gr = gr.map_diag(plt.hist)\n",
    "gr = gr.map_offdiag(plt.scatter)\n",
    "gr = gr.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Understand Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Set up plot size\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "# Attributes destribution\n",
    "a = sns.boxplot(orient=\"v\", palette=\"hls\", data=customer_data.iloc[:, 18], fliersize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Tenure data distribution\n",
    "histogram = sns.distplot(customer_data.iloc[:, 4], hist=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Monthly Charges data distribution\n",
    "histogram = sns.distplot(customer_data.iloc[:, 17], hist=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Total Charges data distribution\n",
    "histogram = sns.distplot(customer_data.iloc[:, 18], hist=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 6. Encode string values in data into numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Use pandas get_dummies\n",
    "customer_data_encoded = pd.get_dummies(customer_data)\n",
    "customer_data_encoded.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 7. Create Training Set and Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create training data for non-preprocessed approach\n",
    "X_npp = customer_data.iloc[:, :-1].apply(LabelEncoder().fit_transform)\n",
    "pd.DataFrame(X_npp).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create training data for that will undergo preprocessing\n",
    "X = customer_data_encoded.iloc[:, :-2]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Extract labels\n",
    "y_unenc = customer_data['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Convert strings of 'yes' and 'no' to binary values of 0 or 1\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_unenc)\n",
    "\n",
    "y_le = le.transform(y_unenc)\n",
    "pd.DataFrame(y_le)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 8. Detect outliers in numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the Z-score using median value and median absolute deviation for more robust calculations\n",
    "# Working on Monthly Charges column\n",
    "threshold = 3\n",
    "\n",
    "median = np.median(X['MonthlyCharges'])\n",
    "median_absolute_deviation = np.median([np.abs(x - median) for x in X['MonthlyCharges']])\n",
    "modified_z_scores = [0.6745 * (x - median) / median_absolute_deviation\n",
    "                         for x in X['MonthlyCharges']]\n",
    "results = np.abs(modified_z_scores) > threshold\n",
    "\n",
    "print(np.any(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Do the same for Total Charges column but using the interquartile method\n",
    "\n",
    "quartile_1, quartile_3 = np.percentile(X['TotalCharges'], [25, 75])\n",
    "iqr = quartile_3 - quartile_1\n",
    "lower_bound = quartile_1 - (iqr * 1.5)\n",
    "upper_bound = quartile_3 + (iqr * 1.5)\n",
    "\n",
    "print(np.where((X['TotalCharges'] > upper_bound) | (X['TotalCharges'] < lower_bound)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 9. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Find interactions between current features and append them to the dataframe\n",
    "def add_interactions(dataset):\n",
    "    # Get feature names\n",
    "    comb = list(combinations(list(dataset.columns), 2))\n",
    "    col_names = list(dataset.columns) + ['_'.join(x) for x in comb]\n",
    "    \n",
    "    # Find interactions\n",
    "    poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "    dataset = poly.fit_transform(dataset)\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    dataset.columns = col_names\n",
    "    \n",
    "    # Remove interactions with 0 values\n",
    "    no_inter_indexes = [i for i, x in enumerate(list((dataset ==0).all())) if x]\n",
    "    dataset = dataset.drop(dataset.columns[no_inter_indexes], axis=1)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X_inter = add_interactions(X)\n",
    "X_inter.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Select best features\n",
    "select = sklearn.feature_selection.SelectKBest(k=25)\n",
    "selected_features = select.fit(X_inter, y_le)\n",
    "indexes = selected_features.get_support(indices=True)\n",
    "col_names_selected = [X_inter.columns[i] for i in indexes]\n",
    "\n",
    "X_selected = X_inter[col_names_selected]\n",
    "X_selected.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 10. Split our dataset into train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Split non-preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_train_npp, X_test_npp, y_train_npp, y_test_npp = train_test_split(X_npp, y_le,\\\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "print(X_train_npp.shape, y_train_npp.shape)\n",
    "print(X_test_npp.shape, y_test_npp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y_le,\\\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Trying to send data to the endpoint will return predictions with probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 11. Scale our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Use StandardScaler\n",
    "scaler = preprocessing.StandardScaler().fit(X_train, y_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "pd.DataFrame(X_train_scaled, columns=X_train.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(y_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 12. Start building a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Support Vector Macines on non-preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Run classifier\n",
    "clf_svc_npp = svm.SVC(random_state=42)\n",
    "clf_svc_npp.fit(X_train_npp, y_train_npp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Support Vector Machines on preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Run classifier\n",
    "clf_svc = svm.SVC(random_state=42)\n",
    "clf_svc.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Logestic Regression on preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_lr = LogisticRegression()\n",
    "model = clf_lr.fit(X_train_scaled, y_train)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Multilayer Perceptron (Neural Network) on preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf_mlp = MLPClassifier(verbose=0)\n",
    "clf_mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Note: MLP as a NN, can use data without the feature engineering step, as the NN will handle that automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 13. Evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Use the scaler fit on trained data to scale our test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "pd.DataFrame(X_test_scaled, columns=X_train.columns).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Evaluate SVC on non-preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Predict confidence scores for data\n",
    "y_score_svc_npp = clf_svc_npp.decision_function(X_test_npp)\n",
    "pd.DataFrame(y_score_svc_npp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Get accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_svc_npp = clf_svc_npp.predict(X_test_npp)\n",
    "acc_svc_npp = accuracy_score(y_test_npp, y_pred_svc_npp)\n",
    "print(acc_svc_npp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Get Precision vs. Recall score\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision_svc_npp = average_precision_score(y_test_npp, y_score_svc_npp)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision_svc_npp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Evaluate SVC on preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Get model confidence of predictions\n",
    "y_score_svc = clf_svc.decision_function(X_test_scaled)\n",
    "y_score_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Get accuracy score\n",
    "y_pred_svc = clf_svc.predict(X_test_scaled)\n",
    "acc_svc = accuracy_score(y_test, y_pred_svc)\n",
    "print(acc_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Get Precision vs. Recall score\n",
    "average_precision_svc = average_precision_score(y_test, y_score_svc)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Evaluate Logistic Regression on preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_score_lr = clf_lr.decision_function(X_test_scaled)\n",
    "y_score_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_lr = clf_lr.predict(X_test_scaled)\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(acc_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "average_precision_lr = average_precision_score(y_test, y_score_lr)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Evaluate MLP on preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_score_mlp = clf_mlp.predict_proba(X_test_scaled)[:, 1]\n",
    "y_score_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_mlp = clf_mlp.predict(X_test_scaled)\n",
    "acc_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "print(acc_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "average_precision_mlp = average_precision_score(y_test, y_score_mlp)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 14. ROC Curve and models comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Plot SVC ROC Curve\n",
    "plt.figure(0, figsize=(20,15)).clf()\n",
    "\n",
    "fpr_svc_npp, tpr_svc_npp, thresh_svc_npp = metrics.roc_curve(y_test_npp, y_score_svc_npp)\n",
    "auc_svc_npp = metrics.roc_auc_score(y_test_npp, y_score_svc_npp)\n",
    "plt.plot(fpr_svc_npp, tpr_svc_npp, label=\"SVC Non-Processed, auc=\" + str(auc_svc_npp))\n",
    "\n",
    "fpr_svc, tpr_svc, thresh_svc = metrics.roc_curve(y_test, y_score_svc)\n",
    "auc_svc = metrics.roc_auc_score(y_test, y_score_svc)\n",
    "plt.plot(fpr_svc, tpr_svc, label=\"SVC Processed, auc=\" + str(auc_svc))\n",
    "\n",
    "fpr_mlp, tpr_mlp, thresh_mlp = metrics.roc_curve(y_test, y_score_mlp)\n",
    "auc_mlp = metrics.roc_auc_score(y_test, y_score_mlp)\n",
    "plt.plot(fpr_mlp, tpr_mlp, label=\"MLP, auc=\" + str(auc_mlp))\n",
    "\n",
    "fpr_lr, tpr_lr, thresh_lr = metrics.roc_curve(y_test, y_score_lr)\n",
    "auc_lr = metrics.roc_auc_score(y_test, y_score_lr)\n",
    "plt.plot(fpr_lr, tpr_lr, label=\"Logistic Regression, auc=\" + str(auc_lr))\n",
    "\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Bonus: Sending the trained model to the cloud and scoring through a web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains Watson Machine Learning service credentials,\n",
    "#  please replace the stars with your own credentials\n",
    "\n",
    "credentials = {\n",
    "  \"apikey\": \"****\",\n",
    "  \"iam_apikey_description\": \"Auto-generated for key ****\",\n",
    "  \"iam_apikey_name\": \"wdp-writer\",\n",
    "  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n",
    "  \"iam_serviceid_crn\": \"****\",\n",
    "  \"instance_id\": \"****\",\n",
    "  \"url\": \"****\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create API client\n",
    "\n",
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "\n",
    "client = WatsonMachineLearningAPIClient(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publish model in Watson Machine Learning repository on Cloud\n",
    "\n",
    "model_props = {client.repository.ModelMetaNames.AUTHOR_NAME: \"ScottDA\", \n",
    "               client.repository.ModelMetaNames.NAME: \"Telco Customer Churn Prediction Model\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_model = client.repository.store_model(model=model, meta_props=model_props, \\\n",
    "                                                training_data=X_train, training_target=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_details = client.repository.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model deployment\n",
    "\n",
    "published_model_uid = client.repository.get_model_uid(published_model)\n",
    "created_deployment = client.deployments.create(published_model_uid, \"Deployment of Customer Churn Prediction Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Scoring URL\n",
    "scoring_endpoint = client.deployments.get_scoring_url(created_deployment)\n",
    "\n",
    "print(scoring_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model details and expected input\n",
    "model_details = client.repository.get_details(published_model_uid)\n",
    "print(json.dumps(model_details, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the payload to be sent to the model\n",
    "payload = {\n",
    "    \"fields\": [\n",
    "        \"tenure\",\n",
    "        \"OnlineSecurity_No\",\n",
    "        \"TechSupport_No\",\n",
    "        \"Contract_Month-to-month\",\n",
    "        \"MonthlyCharges_OnlineSecurity_No\",\n",
    "        \"MonthlyCharges_TechSupport_No\",\n",
    "        \"MonthlyCharges_Contract_Month-to-month\",\n",
    "        \"Dependents_No_OnlineSecurity_No\",\n",
    "        \"Dependents_No_TechSupport_No\",\n",
    "        \"Dependents_No_Contract_Month-to-month\",\n",
    "        \"PhoneService_Yes_Contract_Month-to-month\",\n",
    "        \"InternetService_Fiber optic_OnlineSecurity_No\",\n",
    "        \"InternetService_Fiber optic_TechSupport_No\",\n",
    "        \"InternetService_Fiber optic_Contract_Month-to-month\",\n",
    "        \"InternetService_Fiber optic_PaymentMethod_Electronic check\",\n",
    "        \"OnlineSecurity_No_OnlineBackup_No\",\n",
    "        \"OnlineSecurity_No_TechSupport_No\",\n",
    "        \"OnlineSecurity_No_Contract_Month-to-month\",\n",
    "        \"OnlineSecurity_No_PaymentMethod_Electronic check\",\n",
    "        \"OnlineBackup_No_Contract_Month-to-month\",\n",
    "        \"DeviceProtection_No_Contract_Month-to-month\",\n",
    "        \"TechSupport_No_Contract_Month-to-month\",\n",
    "        \"TechSupport_No_PaymentMethod_Electronic check\",\n",
    "        \"Contract_Month-to-month_PaperlessBilling_Yes\",\n",
    "        \"Contract_Month-to-month_PaymentMethod_Electronic check\"\n",
    " ],\n",
    "    \"values\": [\n",
    "        [20.0, 0.0, 1.0, 0.0, 60.55, 10.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\t\n",
    " ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send data to the model and print results\n",
    "predictions = client.deployments.score(scoring_endpoint, payload)\n",
    "print(json.dumps(predictions, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Sending data to the model\n",
    "\n",
    "Sending new data (may be collected from web/mobile app) in the format the model is excpecting as shown above.  \n",
    "We get back a response with the predicted class (1 - Customer with sent data will churn)  \n",
    "and probabilities of both classes (0 or No Curn has a probability of  1.2567231699733838e-9 which is very small, 1 or Churn has a probability of 0.9999999987432768 which means the model is confident of its prediction)\n",
    "\n",
    "![postman](../doc/source/images/sample_output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References:\n",
    "\n",
    "#### <a name=\"first\" id=\"first\"></a><sub>[1] https://www.sciencedirect.com/science/article/abs/pii/S0148296318301231 \"Customer churn prediction in telecommunication industry using data certainty\"</sub>  \n",
    "#### <a name=\"second\" id=\"second\"></a><sub>[2] https://www.signal.co/blog/understanding-customer-churn/ \"10 Stats Expose the Real Connection Between Customer Experience and Customer Churn\"</sub>  \n",
    "#### <a name=\"third\" id=\"third\"></a><sub>[3] https://www.pinterest.com/pin/456904324667676431/ \"Mobile Telco Churn Infographic\"</sub>  \n",
    "#### <sub>[4] https://pandas.pydata.org/pandas-docs/stable/ \"Pandas Documentation\"</sub>  \n",
    "#### <sub>[5] http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html \"Scikit-Learn Imputer\"</sub>  \n",
    "#### <sub>[6] https://github.com/ibm-watson-data-lab/pixiedust/wiki/Tutorial:-Extending-the-PixieDust-Visualization \"PixieDust Documentation\"</sub>\n",
    "#### <sub>[7] https://seaborn.pydata.org/ \"Seaborn Documentation\"</sub>\n",
    "#### <sub>[8] http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder \"Scikit-Learn LabelEncoder\"</sub>\n",
    "#### <sub>[9] http://colingorrie.github.io/outlier-detection.html \"Outlier Detection Methods\"</sub>\n",
    "#### <sub>[10] http://scikit-learn.org/stable/auto_examples/linear_model/plot_polynomial_interpolation.html#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py \"Scikit-Learn Polynomial\"</sub>\n",
    "#### <sub>[11] http://scikit-learn.org/stable/modules/feature_selection.html \"Scikit-Learn Feature Selection\"</sub>\n",
    "#### <sub>[12] http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler \"Scikit-Learn StandardScaler\"</sub>\n",
    "#### <sub>[13] http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC \"Scikit-Learn SVC\"</sub>\n",
    "#### <sub>[14] http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression \"Scikit-Learn Logistic Regression\"</sub>\n",
    "#### <sub>[15] http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html \"Scikit-Learn MLP Classifier\"</sub>\n",
    "#### <sub>[16] http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score \"Scikit-Learn Accuracy Score\"</sub>\n",
    "#### <sub>[17] http://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score \"Scikit-Learn Average Precision Score\"</sub>\n",
    "#### <sub>[18] https://www.sciencedirect.com/science/article/pii/S016786550500303X \"An introduction to ROC analysis\"</sub>\n",
    "#### <sub>[19] https://wml-api-pyclient.mybluemix.net/ \"Watson Machine Learning Client Documentation\"</sub>\n",
    "#### <sub>[20] https://dataplatform.ibm.com/docs/content/analyze-data/ml-deploy-notebook.html?context=analytics \"IBM Watson Studio Documentation-Deploy a model from a notebook\"</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
